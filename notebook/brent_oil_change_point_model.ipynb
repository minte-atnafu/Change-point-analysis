{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e5c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from datetime import datetime\n",
    "from flask import Flask, jsonify\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1eec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess Brent oil price data\n",
    "df = pd.read_csv('../data/BrentOilPrices.csv')  # Assumes CSV with 'Date' and 'Price' columns\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "df = df.sort_values('Date')\n",
    "prices = df['Price'].values\n",
    "dates = df['Date'].values\n",
    "time_idx = np.arange(len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c9b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "# Plot raw price series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, prices, label='Brent Oil Price (USD)')\n",
    "plt.title('Brent Oil Prices (1987-2022)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD/barrel)')\n",
    "plt.legend()\n",
    "plt.savefig('eda_prices.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1af0933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.993856011392467, p-value: 0.2892735048934032\n"
     ]
    }
   ],
   "source": [
    "# Check stationarity with Augmented Dickey-Fuller test\n",
    "result = adfuller(prices)\n",
    "print(f'ADF Statistic: {result[0]}, p-value: {result[1]}')  # p > 0.05 indicates non-stationarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0f0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot log returns for stationarity\n",
    "log_returns = np.diff(np.log(prices))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates[1:], log_returns, label='Log Returns')\n",
    "plt.title('Log Returns of Brent Oil Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Returns')\n",
    "plt.legend()\n",
    "plt.savefig('eda_log_returns.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa5fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze volatility (30-day rolling standard deviation)\n",
    "rolling_std = pd.Series(log_returns).rolling(window=30).std()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates[1:], rolling_std, label='30-Day Rolling Std Dev')\n",
    "plt.title('Volatility of Brent Oil Log Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.legend()\n",
    "plt.savefig('eda_volatility.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ff75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile event dataset (10-15 major events)\n",
    "events_data = [\n",
    "    {'Event_Date': '1991-01-17', 'Event_Description': 'Gulf War Begins'},\n",
    "    {'Event_Date': '2003-03-20', 'Event_Description': 'Iraq War Begins'},\n",
    "    {'Event_Date': '2008-09-15', 'Event_Description': 'Global Financial Crisis'},\n",
    "    {'Event_Date': '2011-02-15', 'Event_Description': 'Arab Spring Onset'},\n",
    "    {'Event_Date': '2014-06-10', 'Event_Description': 'ISIS Insurgency in Iraq'},\n",
    "    {'Event_Date': '2014-11-27', 'Event_Description': 'OPEC Maintains Production'},\n",
    "    {'Event_Date': '2016-11-30', 'Event_Description': 'OPEC Production Cut'},\n",
    "    {'Event_Date': '2018-05-08', 'Event_Description': 'U.S. Withdraws from Iran Deal'},\n",
    "    {'Event_Date': '2020-03-08', 'Event_Description': 'OPEC+ Price War'},\n",
    "    {'Event_Date': '2020-04-12', 'Event_Description': 'OPEC+ Production Cut'},\n",
    "    {'Event_Date': '2022-02-24', 'Event_Description': 'Russia-Ukraine Conflict Begins'},\n",
    "]\n",
    "events = pd.DataFrame(events_data)\n",
    "events['Event_Date'] = pd.to_datetime(events['Event_Date'])\n",
    "events.to_csv('events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f633fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [tau]\n",
      ">NUTS: [mu, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\mintesinot\\week_10\\venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\mintesinot\\week_10\\venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 747 seconds.\n",
      "There were 231 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling failed: 'functools.partial' object has no attribute '__name__'\n",
      "<xarray.Dataset> Size: 368kB\n",
      "Dimensions:           (chain: 2, draw: 2000, tau_dim_0: 3, mu_dim_0: 4,\n",
      "                       tau_sorted_dim_0: 3)\n",
      "Coordinates:\n",
      "  * chain             (chain) int64 16B 0 1\n",
      "  * draw              (draw) int64 16kB 0 1 2 3 4 5 ... 1995 1996 1997 1998 1999\n",
      "  * tau_dim_0         (tau_dim_0) int64 24B 0 1 2\n",
      "  * mu_dim_0          (mu_dim_0) int64 32B 0 1 2 3\n",
      "  * tau_sorted_dim_0  (tau_sorted_dim_0) int64 24B 0 1 2\n",
      "Data variables:\n",
      "    tau               (chain, draw, tau_dim_0) int64 96kB 60 60 30 ... 30 60 60\n",
      "    mu                (chain, draw, mu_dim_0) float64 128kB -0.02669 ... -0.2788\n",
      "    sigma             (chain, draw) float64 32kB 0.09598 0.09458 ... 0.09148\n",
      "    tau_sorted        (chain, draw, tau_sorted_dim_0) int64 96kB 30 60 ... 60 60\n",
      "Attributes:\n",
      "    created_at:                 2025-08-06T08:04:23.958199+00:00\n",
      "    arviz_version:              0.22.0\n",
      "    inference_library:          pymc\n",
      "    inference_library_version:  5.25.1\n",
      "    sampling_time:              747.3293838500977\n",
      "    tuning_steps:               1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "# Disable C compiler to use Python backend\n",
    "pytensor.config.cxx = \"\"\n",
    "pytensor.config.mode = \"FAST_RUN\"\n",
    "\n",
    "# Synthetic data for testing (replace with your actual log_returns and time_idx)\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "log_returns = np.concatenate([\n",
    "    np.random.normal(0, 0.1, 30),\n",
    "    np.random.normal(0.5, 0.1, 30),\n",
    "    np.random.normal(-0.3, 0.1, 40)\n",
    "])\n",
    "time_idx = np.arange(n + 1)  # time_idx should be one element longer than log_returns\n",
    "\n",
    "with pm.Model() as multi_cp_model:\n",
    "    n_change_points = 3\n",
    "    # DiscreteUniform for change points\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=len(log_returns)-1, shape=n_change_points)\n",
    "    # Sort tau to ensure ordered change points\n",
    "    tau_sorted = pm.Deterministic(\"tau_sorted\", pt.sort(tau))\n",
    "    \n",
    "    # Priors for means and standard deviation\n",
    "    mu = pm.Normal(\"mu\", mu=0, sigma=0.1, shape=n_change_points+1)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=0.1)\n",
    "    \n",
    "    # Define piecewise mean using switch\n",
    "    idx = time_idx[:-1]  # Match length of log_returns\n",
    "    mu_t = pm.math.switch(idx < tau_sorted[0], mu[0],\n",
    "                          pm.math.switch(idx < tau_sorted[1], mu[1],\n",
    "                                         pm.math.switch(idx < tau_sorted[2], mu[2], mu[3])))\n",
    "    \n",
    "    # Likelihood\n",
    "    likelihood = pm.Normal(\"likelihood\", mu=mu_t, sigma=sigma, observed=log_returns)\n",
    "    \n",
    "    # MCMC sampling with single core to avoid pickling issues\n",
    "    trace = pm.sample(2000, tune=1000, return_inferencedata=True, cores=1)\n",
    "\n",
    "# Optional: Verify model is picklable\n",
    "import pickle\n",
    "try:\n",
    "    pickle.dumps(multi_cp_model)\n",
    "    print(\"Model is picklable\")\n",
    "except Exception as e:\n",
    "    print(\"Pickling failed:\", e)\n",
    "\n",
    "# Print summary of trace\n",
    "print(trace.posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f480c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mintesinot\\week_10\\venv\\Lib\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
      "c:\\Users\\mintesinot\\week_10\\venv\\Lib\\site-packages\\arviz\\stats\\diagnostics.py:991: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  varsd = varvar / evar / 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "tau_sorted[0]  30.000  0.000  30.000   30.000      0.000      NaN    4000.0   \n",
      "tau_sorted[1]  60.000  0.000  60.000   60.000      0.000      NaN    4000.0   \n",
      "tau_sorted[2]  61.014  3.136  60.000   68.000      1.144    1.722       9.0   \n",
      "mu[0]          -0.018  0.017  -0.049    0.014      0.001    0.000     858.0   \n",
      "mu[1]           0.473  0.017   0.440    0.504      0.000    0.000    1434.0   \n",
      "mu[2]          -0.040  0.131  -0.326    0.148      0.030    0.020      25.0   \n",
      "mu[3]          -0.296  0.015  -0.325   -0.270      0.001    0.000     831.0   \n",
      "sigma           0.093  0.007   0.081    0.105      0.000    0.000    1353.0   \n",
      "\n",
      "               ess_tail  r_hat  \n",
      "tau_sorted[0]    4000.0    NaN  \n",
      "tau_sorted[1]    4000.0    NaN  \n",
      "tau_sorted[2]      12.0   1.17  \n",
      "mu[0]             538.0   1.00  \n",
      "mu[1]            3095.0   1.00  \n",
      "mu[2]              26.0   1.06  \n",
      "mu[3]            1171.0   1.00  \n",
      "sigma            2418.0   1.00  \n"
     ]
    }
   ],
   "source": [
    "# Model diagnostics\n",
    "print(az.summary(trace, var_names=[\"tau_sorted\", \"mu\", \"sigma\"]))\n",
    "az.plot_trace(trace, var_names=[\"tau_sorted\", \"mu\", \"sigma\"])\n",
    "plt.savefig('model_diagnostics.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43274151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Change Points:\n",
      "Change Point 1: 1987-07-03\n",
      "Change Point 2: 1987-08-14\n",
      "Change Point 3: 1987-08-14\n"
     ]
    }
   ],
   "source": [
    "# Extract change points\n",
    "tau_modes = [int(np.bincount(trace.posterior[\"tau_sorted\"].values[:, :, i].flatten()).argmax()) \n",
    "             for i in range(n_change_points)]\n",
    "change_point_dates = [dates[tau + 1] for tau in tau_modes]  # Adjust for log returns offset\n",
    "\n",
    "# Print change points with proper date formatting\n",
    "print(\"Detected Change Points:\")\n",
    "for i, cp_date in enumerate(change_point_dates):\n",
    "    cp_date = pd.to_datetime(cp_date)  # Convert numpy.datetime64 to Timestamp\n",
    "    print(f\"Change Point {i+1}: {cp_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926a2f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 0 to 1: Mean log return from -0.0175 to 0.4732, Estimated price change: 63.35%\n",
      "Segment 1 to 2: Mean log return from 0.4732 to -0.0404, Estimated price change: -40.17%\n",
      "Segment 2 to 3: Mean log return from -0.0404 to -0.2964, Estimated price change: -22.59%\n"
     ]
    }
   ],
   "source": [
    "# Quantify impact\n",
    "mu_means = trace.posterior[\"mu\"].mean(dim=[\"chain\", \"draw\"]).values\n",
    "for i in range(n_change_points):\n",
    "    price_change_percent = (np.exp(mu_means[i+1]) - np.exp(mu_means[i])) / np.exp(mu_means[i]) * 100\n",
    "    print(f\"Segment {i} to {i+1}: Mean log return from {mu_means[i]:.4f} to {mu_means[i+1]:.4f}, \"\n",
    "          f\"Estimated price change: {price_change_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b24f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cp_date in change_point_dates:\n",
    "    cp_date = pd.to_datetime(cp_date)  # Convert numpy.datetime64 to Timestamp\n",
    "\n",
    "    relevant_events = events[\n",
    "        (events['Event_Date'] >= cp_date - window) &\n",
    "        (events['Event_Date'] <= cp_date + window)\n",
    "    ]\n",
    "\n",
    "    if not relevant_events.empty:\n",
    "        closest_event = relevant_events.iloc[0]\n",
    "        change_point_events.append({\n",
    "            'Change_Point_Date': cp_date.strftime('%Y-%m-%d'),\n",
    "            'Event_Date': pd.to_datetime(closest_event['Event_Date']).strftime('%Y-%m-%d'),\n",
    "            'Event_Description': closest_event['Event_Description']\n",
    "        })\n",
    "    else:\n",
    "        change_point_events.append({\n",
    "            'Change_Point_Date': cp_date.strftime('%Y-%m-%d'),\n",
    "            'Event_Date': 'N/A',\n",
    "            'Event_Description': 'No event within ±7 days'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18c02ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save change point results\n",
    "change_points_df = pd.DataFrame(change_point_events)\n",
    "change_points_df.to_csv('change_points.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a817caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price series with change points and events\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(dates, prices, label='Brent Oil Price')\n",
    "\n",
    "# Plot change points with labels only on the first one\n",
    "for i, cp_date in enumerate(change_point_dates):\n",
    "    cp_date = pd.to_datetime(cp_date)  # Convert to pandas Timestamp\n",
    "    label = f\"Change Point: {cp_date.strftime('%Y-%m-%d')}\" if i == 0 else \"\"\n",
    "    plt.axvline(cp_date, color='r', linestyle='--', label=label)\n",
    "\n",
    "# Plot events with label only on the first one\n",
    "for i, event in events.iterrows():\n",
    "    event_date = pd.to_datetime(event['Event_Date'])\n",
    "    label = 'Events' if i == 0 else \"\"\n",
    "    plt.axvline(event_date, color='g', linestyle=':', alpha=0.5, label=label)\n",
    "\n",
    "plt.title('Brent Oil Prices with Change Points and Events')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD/barrel)')\n",
    "plt.legend()\n",
    "plt.savefig('price_with_change_points.png')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
